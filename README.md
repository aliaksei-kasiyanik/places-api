# Places API

## Архитектура системы

### Прикладная область

  Чтобы определить гарантии, которые Places API должен обеспечивать, сначала определим область применения данного веб-сервиса.
Предполагается, что данный веб-сервис в первую очередь будет использоваться приложениями-планировщиками туристических путешествий. 

  Приложение, использующее Places API, будет позволять пользователям осуществлять поиск POI в некоторой области по заданным координатам геолокации и создавать списки/коллекции мест, которые он хотел бы посетить. 
  
  Для наполнения существующей базы данных POI пользователь может сам добавлять места (POI), которых нет в базе. Такие места станут видны другим пользователям после проверки и утверждения администратором.
  
  Также пользователь может оставлять комментарии относительно POI и оценивать POI методом "thumbs-up/thumbs-down". Также предполагается возможность загрузки фотографий POI пользователем. 
  
  Пользователь может вносить/предлагать изменения в информацию о POI, которые будут применяться только после модерации администратором в целях защиты от вандализма, например, вредительского добавления, удаления или изменения содержания. 

 **Note!** Реализация REST API для приведенного выше функционала может занять большое количество времени, поэтому в рамках курса будет реализован базовый API по работе c POI (см. https://aliaksei-kasiyanik.github.io/), однако изначальная архитектура будет строиться таким образом, чтобы реализация всего функционала или его расширение происходила без критических изменений в архитектуре.
 
 Places API рассматривается как высоконагруженный веб-сервис, способный быстро отвечать на запросы, приходящие из любой точки мира.

### CAP Theorem

  Учитывая особенности распреденных систем, рассматриваемых CAP теоремой (https://en.wikipedia.org/wiki/CAP_theorem), определим каким гарантиям наша система должна соответствовать в терминах CAP теоремы, основываясь на бизнесс-логике и области применения данного веб-сервиса. 

  В первую очередь последовательно рассмотрим базовый функционал (см. https://aliaksei-kasiyanik.github.io/) с точки зрения CAP теоремы:
* /places GET - поиск POI в заданном регионе; возвращает список POI.
  Нам необходима высокая доступность данного ресурса (availability), т.к. он является ключевым в нашем сервисе. При этом ресурс требует только доступность на чтение. Устойчивость к разделению  сети (partition tolerance) также необходима в данном случае: если, например, Ктулху перегрызет межконтинентальный кабель между Европой и Америкой на дне Атлантического океана, данный ресурс должен продолжать отвечать и в Европе, и в Америке. Консистентность данных здесь не так критична, так как ее нарушение не блокирует работу и не влечет критических последствий в текущий момент времени.
  Таким образом нам нужны гарантии **AP (A - на чтение)**.
  
* /places/{id} GET - возвращает полную информация о конкретном POI
 То же как и для /places GET. **AP (A - на чтение)**
  
* /places POST - добавление новых POI; данный ресурс доступен только администраторам.
  Функция добавления нового POI не критична с точки зрения availability, так как не доступна обычным пользователям и никаким образом не влияет на его работу, а администратор будет осведомлен о проблемах доступности данного ресурса и сможет добавить POI позже после восстановления системы. С точки зрения consistency нам важно, чтобы после применения данной операции POI был виден со всех узлов, иначе возможна ситуация, когда запрос поиска попадет на один узел, на котором POI уже добавлен, а следующий запрос на получение полной информации (например, с комментариями и фотографиями) попадет на узел, где данного POI еще нет.
  То есть получаем - **СP**.  

* /places/{id} PUT - модификация существующего POI; данный ресурс доступен только администраторам.
  Обновление информации о POI не имеет особо влияния на работу пользователя, поэтому строгая консистентность не нужна, однако ожидается, что информация о POI гарантировано будет консистентной через некоторый промежуток времени. Availability можно пожертвовать по тем же причинам, что и в /places POST, поэтому нам подойдет **СP (C - eventual)**.

* /places/{id} DELETE - удаление новых POI; данный ресурс доступен только администраторам.
  Те же соображения, как и для /places/{id} PUT.
  **СP (C - eventual)**
  
  
  *Рассмотрим функционал, который не планируется реализовывать в учебном проекте (хотя вероятность есть):*

* /places/{id}/comment POST - добавление комментария к POI;  комментарии предоставляются вместе с другой информацией о POI c помощью /places/{id} GET
  Важно availability, так как мнение пользователей важно и интересно другим пользователям и имеет часто определяющее значение при выборе посетить данное место или нет. Необходимо гарантировать, что добавленные пользователем комментарии должны быть сразу видны пользователем, который их добавил. Также необходима eventual consistency, чтобы другие пользователи в конечном счете увидели комментарии других пользователей. Комментарии можем рассматривать как CRDT.
  Поэтому здесь желательно **AP c eventual consistency**.

* /places/{id}/vote PUT - голосование "thumbs-up/thumbs-down"
 CRDT. В общем те же соображения как и для добавления комментариев. **AP c eventual consistency**

* /places/{id}/image POST - добавление фотографии; добавленные фотографии возвращаются вместе с другой информацией о POI c помощью /places/{id} GET
 CRDT. Те же соображения как и для добавления комментариев. **AP c eventual consistency**
  
* /new-places POST - добавление новых POI пользователем в общую базу; POI в базу сразу не попадают, а проходят модерацию администратором
  Если рассмотреть возможность добавления точек любым пользователем, то важна availability, а не consistency, так как новый POI станет общедоступным только после проверки администратором, а для этого в любом случае нужно время. **AP c eventual consistency** 
  
  
#### Обобщение
 Исходя из соображений выше, нам лучше всего подходит AP система c eventual consistency, а для администраторского функционала нужны CP гарантии. 
 
### Технологии и построение архитектуры
   Сколько-нибудь глубоко проанализировать весь спектр существующих технологий в сфере распределенных баз данных не представляется возможным, поэтому рассмотрим ключевые моменты в наиболее популярных решениях.
  Исходя из специфики данных, а также выше приведенных выкладок, касающихся CAP теоремы, хорошим решением будет использование документоориентированной (или key-value?) системы управления базами данных AP типа с поддержкой CRDT и геопространственных данных. 
  Рассмотрим варианты:
  
1. Riak KV - AP  

  Pros:
  * Masterless
  * Наличие CRDT
  * Поддержка автоматического утстранения конфликтов
  
  Cons:  
  * Требуется интеграция с Apache Solr для эффективной выборки данных
  * Нет поддержки геопространственных данных (возможно индексирование с помощью Solr, однако не знаю, насколько эффективно)

2. MongoDB - CP 

  Pros:
  * Документоориентированная база
  * Подержка geospatial indices
  * Мощный встроенные query-функционал
  
  Cons:  
  * Master-slave => availability?
  * Отсутствие CRDT

3. Couchbase Server - CP in cluster - AP with several clusters

  Pros:
  * Document-oriented 
  * Geographic Distribution and Cross Data Center Replication (XDCR)
  * CP if running as a single cluster - AP with XDCR with several clusters (eventual consistency)
  
  Cons:
  * Some features are available only in enterprise version
  
### Архитектура
  Так как такие системы как Couchbase и Riak являются достаточно сложными и на их изучение требуется большое количество времени, я решил остановиться на варианте с MongoDB и Go как backend-языком. 
  В полном варианте (со всем функционалом) система на мой взгляд могла бы выглядеть следующим образом:
 ![alt text](https://raw.githubusercontent.com/aliaksei-kasiyanik/places-api/master/PlaceAPI.png "Architecture Design")
 Вся система будет делиться на несколько подсистем, размещенных в разных географических регионах. Каждая подсистема является по большому счету независимой и включает в себя 2 сервера с развернутыми на них REST-сервисами (на языке Go), 2 Nginx сервера (Active и Passive) и MongoDB кластер, состоящий из 3 инстансов. Таким образом получаем распределенную систему с гарантией, что она может корректно работать при потере одной любой ноды на каждом уровне. Помимо подсистем, которые непосредственно отвечают на запросы клиентов, будеи подсистема, работающая в качестве central repository и осуществляющая синхронизацию. Эта подсистема будет состоять из MongoDB кластера, состоящего из 3 инстансов с чтением и записью через primary node и нескольких master-slave серверов, осуществляющих синхронизацию подсистем и central repository. CRDT-данные, такие как комментарии, рейтинг, а также неконфликтующие изменения в POI будут синхронизироваться между подсистемами автоматически, иначе - через некий интерфейс администратором.
 Теперь рассмотрим поведение и гарантии, которые мы получим при работе такой системы.
 
 1. Географическая сегментация системы позволит нам существенно уменьшить network latency, так как, например, клиентам из США не нужно посылать запросы в Европу.
 
 2. Ноды полноценного MongoDB кластера будет находится в географической близости, что также позволит ускорить процесс репликации между ними.
 
 3. Компактное расположение серверов в подсистеме уменьшает количество network узлов между ними, тем самым уменьшая вероятность network partition.
 
 4. Back-end сервера в данной модели являются stateless и независимыми друг от друга, поэтому данный слой системы легко масштабируется  горизонтально путем добавления нового инстанса и конфигурации Nginx. 
 
 5. MongoDB будет настроена таким образом, что read-запросы на редко изменяющиеся и/или не требующие строгой согласованности данных будут распределяться равномерно и на primary, и на secondary ноды. К таким запросам относятся /places GET (поиск точек в заданном регионе по набору параметров) и /places/{id} GET (запрос полной информации о конкретном POI с комментариями и рейтингом)
    Запросы на запись /places POST - добавление новый точек, который применяется на primary node и далее реплицироваться, может вызвать эффект "фантомных" точек. Например, какая-то новая точка была добавлена в primary node, далее запрос клиента попал на primary node и эта точка попала в ответ клиенту среди прочих, потом клиет свой запрос повторяет, но он уже попадает на secondary node, на который эта точка еще не успела среплицироваться, как следствие, клиент этой точки уже не видит. Однако, такой эффект совершенно не критичен + точки будут добавляться администратором  очень редко. Такое же поведение приемлимо и /places/{id} PUT и /places/{id} DELETE.

6. Добавление комментариев или оценка также не требует согласованности от MongoDB, так как только пользователю важно сразу видеть, что комментарий добавлен. Это легко реализуется с помощью кэширования (с небольшим lifetime) на стороне клиента. Мгновенно видеть чужой комментарий или обновление рейтинга пользователям не важно. Такое же поведение приемлимо и для добавления фотографий (за непосредственное хранение фото наш сервис не отвечает, в базе хранятся URLs).
 
 7. Добавление комментариев, фотографий и оценка в большинстве случаев будут осуществляться в непосредственной близости от POI и для нас важнее, чтобы комментарий о какой-то точке в Нью-Йорке был быстрее виден пользователям из Нью-Йорка, а не из Минска. Сегментация на независимые подсистемы позволяет нам это делать эффективнее.
 
8. В случае отщепления региона от сети, он продолжает обслуживать запросы на чтение и на запись. После восстановления сети с регионом синхронизация будет происходить через central repository, так как он продолжал синхронизироваться с другими подсистемами, как следствие, нагрузка по синхронизации в меньшей степени заденет другие подсистемы и не повлияет на их производительность.
